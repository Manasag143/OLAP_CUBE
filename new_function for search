import logging
import time
import json
import os
import requests
import yaml
from datetime import date
from colorama import Fore, Style, init
from typing import Dict, List, Tuple, Optional

from langchain_core.documents import Document
from langchain_community.vectorstores.chroma import Chroma
from langchain_openai import AzureOpenAIEmbeddings
from langchain.chains import RetrievalQA
from langchain_openai import AzureChatOpenAI
from langchain_community.callbacks import get_openai_callback
from langchain.prompts import PromptTemplate
from langchain_community.retrievers import BM25Retriever
from langchain.retrievers import EnsembleRetriever


BASE_DIR = os.path.dirname(os.path.abspath(__file__))
CUBE_DETAILS_DIR = os.path.join(BASE_DIR, "cube_details")
IMPORT_HISTORY_FILE = os.path.join(BASE_DIR, "import_history.json")
history_file = os.path.join(BASE_DIR, "conversation_history.json")
vector_db_path = os.path.join(BASE_DIR, "vector_db")
config_file = os.path.join(BASE_DIR, "config.json")

def load_documents_from_json(cube_id: str, doc_type: str, base_dir: str) -> List[Document]:
    """Load documents from JSON file"""
    try:
        file_path = os.path.join(base_dir, cube_id, f"{cube_id}_{doc_type}.json")
        
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"Cube data doesn't exist")
            
        with open(file_path) as f:
            data = json.load(f)
            
        # Convert to Document objects
        documents = []
        for doc in data:
            content = f"Group Name:{doc['Group Name']}--Level Name:{doc['Level Name']}--Description:{doc['Description']}"
            documents.append(Document(page_content=content))
        return documents
            
    except Exception as e:
        logging.error(f"Error loading {doc_type} documents: {str(e)}")
        raise

def setup_logging():
    """Store errors in log folder datewise and token consumptions."""
    today = date.today()
    log_folder = './log'
  
    if not os.path.exists(log_folder):
        os.mkdir(log_folder)
    
    logging.basicConfig(
        filename=f"{log_folder}/{today}.log",
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s'
    )

class SmartFunctionsManager:
    """Simple function manager - loads YAML and uses LLM to get functions"""
    
    def __init__(self, functions_file: str = "olap_functions.yaml", llm: AzureChatOpenAI = None):
        self.llm = llm
        # Load YAML file
        with open(functions_file, 'r', encoding='utf-8') as f:
            self.functions_library = yaml.safe_load(f)
        
        # Make flat list of all functions
        self.all_functions = {}
        for category, functions in self.functions_library.items():
            for func_name, func_info in functions.items():
                self.all_functions[func_name] = func_info
    
    def build_dynamic_functions_section(self, query: str) -> str:
        """Get functions from LLM prompt"""
        
        # Create function list for LLM
        functions_text = "Available Functions:\n"
        for func_name, func_info in self.all_functions.items():
            functions_text += f"- {func_name}: {func_info['syntax']}\n"
            functions_text += f"  Use: {func_info.get('use_case', '')}\n"
            functions_text += f"  Example: {func_info['example']}\n\n"
        
        # Ask LLM which functions needed
        prompt = f"""Look at this query and tell me which OLAP functions are needed.

{functions_text}

Query: "{query}"

Examples:
- "Top 5 cities" needs: Head
- "Between 2020-2023" needs: TimeBetween  
- "Bottom 3 states" needs: Tail
- "Count by region" needs: NONE

Just give me function names separated by commas, or "NONE" if no special functions needed.
Response format: Head, TimeBetween OR NONE"""

        # Get LLM response
        response = self.llm.invoke(prompt)
        selected_text = response.content.strip()
        
        # Build result
        if selected_text.upper() == "NONE":
            return "<functions>\nNo special functions needed.\n</functions>"
        
        result = "<functions>\n"
        for func_name in selected_text.split(','):
            func_name = func_name.strip()
            if func_name in self.all_functions:
                func_info = self.all_functions[func_name]
                result += f"- {func_name}: {func_info['syntax']}\n"
                result += f"  Example: {func_info['example']}\n"
        result += "</functions>"
        
        return result

class LLMConfigure:
    """Class responsible for loading and configuring LLM and embedding models from a config file."""

    def __init__(self, config_path: str = "config.json"):
        self.config = self.load_config(config_path)
        self.llm = None
        self.embedding = None

    def load_config(self, config_path: str) -> Dict:
        """Loads the config from a JSON file."""
        try:
            with open(config_path, 'r') as config_file:
                config = json.load(config_file)
                return config
        except FileNotFoundError as e:
            logging.error(f"Config file not found: {e}")
            raise
        except json.JSONDecodeError as e:
            logging.error(f"Error parsing the config file: {e}")
            raise

    def initialize_llm(self):
        """Initializes and returns the LLM model."""
        try:
            self.llm = AzureChatOpenAI(
                openai_api_key=self.config['llm']['OPENAI_API_KEY'],
                model=self.config['llm']['model'],
                temperature=self.config['llm']['temperature'],
                api_version=self.config['llm']["OPENAI_API_VERSION"],
                azure_endpoint=self.config['llm']["AZURE_OPENAI_ENDPOINT"],
                seed=self.config['llm']["seed"]
            )
            return self.llm
        except KeyError as e:
            logging.error(f"Missing LLM configuration in config file: {e}")
            raise

    def initialize_embedding(self):
        """Initializes and returns the Embedding model."""
        try:
            self.embedding = AzureOpenAIEmbeddings(
                deployment=self.config['embedding']['deployment'],
                azure_endpoint=self.config['llm']["AZURE_OPENAI_ENDPOINT"],
                openai_api_key=self.config['llm']['OPENAI_API_KEY'],
                show_progress_bar=self.config['embedding']['show_progress_bar'],
                disallowed_special=(),
                openai_api_type=self.config['llm']['OPENAI_API_TYPE']
            )
            return self.embedding
        except KeyError as e:
            logging.error(f"Missing embedding configuration in config file: {e}")
            raise

class DimensionMeasure:
    """Class responsible for extracting dimensions and measures from the natural language query."""

    def __init__(self, llm: str, embedding: str, vectorstore: str):
        self.llm = llm
        self.embedding = embedding
        self.vector_embedding = vectorstore

    def get_dimensions(self, query: str, cube_id: str, prev_conv: dict) -> str:
        """Extracts dimensions from the query."""
        try:
            with get_openai_callback() as dim_cb:
                query_dim = """ 
                As an SQL CUBE query expert, analyze the user's question and identify all relevant cube dimensions from the dimensions delimited by ####.
                
                <instructions>
                - Select relevant dimension group, level, description according to user query from dimensions list delimited by ####
                - format of one dimension: Group Name:<Group Name>--Level Name:<Level Name>--Description:<Description> 
                - Include all dimensions relevant to the question in the response
                - Group Name and Level Name can never be same, extract corresponding group name for a selected level name according to the user query and vice versa.
                - If relevant dimensions group and level are not present in the dimensions list, please return "Not Found"
                - If the query mentions date, year, month ranges, include corresponding dimensions in the response  
                </instructions>
                
                Response format:
                Group Name:<Group Name>--Level Name:<Level Name>--Description:<Description>

                Review:
                - ensure dimensions are only selected from dimensions list delimited by ####
                - Group Name and Level Name can never be same, extract corresponding group name, description for a selected level name according to the user query and vice versa.
                - Kindly ensure that the retrieved dimensions group name and level name is present otherwise return "Not found".

                User Query: {question}
                ####
                {context}
                ####
                """

                print(Fore.RED + '    Identifying Dimensions group name and level name......................\n')
                
                # Load documents from JSON
                documents = load_documents_from_json(cube_id, "dimensions", vector_db_path)
                
                # Initialize BM25 retriever
                bm25_retriever = BM25Retriever.from_documents(documents, k=10)
                    
                # Set up vector store directory
                cube_dir = os.path.join(vector_db_path, cube_id)
                cube_dim = os.path.join(cube_dir, "dimensions")
                
                load_embedding_dim = Chroma(persist_directory=cube_dim, embedding_function=self.embedding)
                vector_retriever = load_embedding_dim.as_retriever(search_type="similarity", search_kwargs={"k": 20})

                # Create ensemble retriever
                ensemble_retriever = EnsembleRetriever(
                    retrievers=[bm25_retriever, vector_retriever],
                    weights=[0.5, 0.5]
                )
                
                # Initialize and run QA chain
                qa_chain = RetrievalQA.from_chain_type(
                    llm=self.llm,
                    retriever=ensemble_retriever,
                    return_source_documents=True,
                    verbose=True,
                    chain_type_kwargs={
                        "prompt": PromptTemplate(
                            template=query_dim,
                            input_variables=["query", "context"]
                        ),
                        "verbose": True
                    }
                )

                # Get results
                result = qa_chain({"query": query, "context": ensemble_retriever})
                dim = result['result']
                print(Fore.GREEN + '    Identified Group and level name :        ' + str(dim))
                logging.info(f"Extracted dimensions :\n {dim}")
                return dim

        except Exception as e:
            logging.error(f"Error extracting dimensions : {e}")
            raise

    def get_measures(self, query: str, cube_id: str, prev_conv: dict) -> str:
        """Extracts measures from the query."""
        try:
            with get_openai_callback() as msr_cb:
                query_msr = """ 
                As an SQL CUBE query expert, analyze the user's question and identify all relevant cube measures from the measures delimited by ####.
                
                <instructions>
                - Select relevant measure group, level, description according to user query from measures list delimited by ####
                - format of one measure: Group Name:<Group Name>--Level Name:<Level Name>--Description:<Description> 
                - Include all measures relevant to the question in the response
                - Group Name and Level Name can never be same, extract corresponding group name for a selected level name according to the user query and vice versa.
                - If relevant measures are not present in the measures list, please return "Not Found" 
                </instructions>

                Response format:
                Group Name:<Group Name>--Level Name:<Level Name>--Description:<Description>

                Review:
                - Ensure measures are only selected from measures list delimited by ####
                - Group Name and Level Name can never be same, extract corresponding group name, description for a selected level name according to the user query and vice versa.
                - Kindly ensure that the retrieved measures group name and level name is present otherwise return "Not found".

                User Query: {question}
                ####
                {context}
                ####
                """

                print(Fore.RED + '    Identifying Measure group name and level name......................\n')
                
                # Load documents from JSON
                documents = load_documents_from_json(cube_id, "measures", vector_db_path)
                
                bm25_retriever = BM25Retriever.from_documents(documents, k=10)

                cube_msr = os.path.join(vector_db_path, cube_id, "measures")
                load_embedding_msr = Chroma(persist_directory=cube_msr, embedding_function=self.embedding)
                vector_retriever = load_embedding_msr.as_retriever(search_type="similarity", search_kwargs={"k": 20})
                
                ensemble_retriever = EnsembleRetriever(
                    retrievers=[bm25_retriever, vector_retriever],
                    weights=[0.5, 0.5]
                )

                # Run QA chain with ensemble retriever
                qa_chain = RetrievalQA.from_chain_type(
                    llm=self.llm,
                    retriever=ensemble_retriever,
                    return_source_documents=True,
                    verbose=True,
                    chain_type_kwargs={
                        "prompt": PromptTemplate(
                            template=query_msr,
                            input_variables=["query", "context"]
                        ),
                        "verbose": True
                    }
                )
                
                result = qa_chain({"query": query, "context": ensemble_retriever})
                msr = result['result']

                print(Fore.GREEN + '    Measures result :        ' + str(result)) 
                logging.info(f"Extracted measures :\n {msr}")  
                return msr
        
        except Exception as e:
            logging.error(f"Error Extracting Measure: {e}")
            raise

class FinalQueryGenerator(LLMConfigure):
    """Class responsible for generating the final OLAP query based on dimensions and measures."""
    
    def __init__(self, query, dimensions: None, measures: None, llm: None):
        super().__init__()
        self.query = query
        self.dimensions = dimensions
        self.measures = measures
        self.llm = llm
        self.functions_manager = SmartFunctionsManager("olap_functions.yaml", llm)
        
    def call_gpt(self, final_prompt: str):
        """Function responsible for generating final query"""
        API_KEY = self.config['llm']['OPENAI_API_KEY']
        headers = {
            "Content-Type": "application/json",
            "api-key": API_KEY,
        }
        
        payload = {
            "messages": [
                {
                    "role": "system",
                    "content": [
                        {
                            "type": "text",
                            "text": "You are an AI assistant that writes accurate OLAP cube queries based on given query."
                        }
                    ]
                },
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": final_prompt
                        }
                    ]
                }
            ],
            "temperature": self.config['llm']['temperature'],
            "top_p": self.config['llm']['top_p'],
            "max_tokens": self.config['llm']['max_tokens']
        }
        
        ENDPOINT = self.config['llm']['ENDPOINT']
        
        try:
            response = requests.post(ENDPOINT, headers=headers, json=payload)
            response.raise_for_status()
        except requests.RequestException as e:
            raise SystemExit(f"Failed to make the request. Error: {e}")
        
        output = response.json()
        token_details = output['usage']
        output = output["choices"][0]["message"]["content"]
        return output, token_details

    def generate_query(self, query: str, dimensions: str, measures: str, prev_conv: dict, cube_name: str) -> str:
        try:
            # Get functions from LLM
            dynamic_functions = self.functions_manager.build_dynamic_functions_section(query)
                
            final_prompt = f"""You are an expert in generating SQL Cube query. You will be provided dimensions delimited by $$$$ and measures delimited by &&&&.
            Your Goal is to generate a precise single line cube query for the user query delimited by ####.

            Instructions:            
            - Generate a single-line Cube query without line breaks
            - Include 'as' aliases for all level names in double quotes. alias are always level names.
            - Choose the most appropriate dimensions group names and level from dimensions delimited by $$$$ according to the query.
            - Choose the most appropriate measures group names and level from measures delimited by &&&& according to the query.
            - check the examples to learn about correct syntax, functions and filters which can be used according to the user query requirement.
            - User Query could be a follow up query in a conversation, you will also be provided previous query, dimensions, measures, cube query. Generate the final query including the contexts from conversation as appropriate.

            Formatting Rules:
            - Dimensions format: [Dimension Group Name].[Dimension Level Name] as "Dimension Level Name"
            - Measures format: [Measure Group Name].[Measure Level Name] as "Measure Level Name"
            - Conditions in WHERE clause must be properly formatted with operators
            - For multiple conditions, use "and" "or" operators
            - All string values in conditions must be in single quotes
            - All numeric values should not have leading zeros
            
            {dynamic_functions}
